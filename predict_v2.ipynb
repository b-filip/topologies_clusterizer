{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from path import Path  # pip install --user path.py\n",
    "import re\n",
    "from IPython.display import display\n",
    "from pprint import pprint\n",
    "import netCDF4\n",
    "from IPython.core.debugger import Pdb\n",
    "from collections import namedtuple\n",
    "from random import randint, choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load seaborn and other stuff for visualization\n",
    "import seaborn  # pip install --user seaborn\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def debug_here():\n",
    "    Pdb().set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = pd.read_pickle(\"classes.pkl\")\n",
    "node_pairs = pd.read_pickle(\"paths_with_classes.pkl\").drop(\"shortest_path\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST_RESULT_DIRECTORIES = Path(\"/home/shibbiry/Dropbox/documents/msu/bachelors_thesis_cluster_topology/test_results\") \\\n",
    "    .dirs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_benchmark_hostnames(path_to_file):\n",
    "    lines = path_to_file.lines()\n",
    "    return (re.match(r\"^(n\\d{5})\\.\", line).groups()[0] for line in lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TestResults = namedtuple(\"TestResults\", [\"hostnames\", \"medians\", \"msg_lengths\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def import_data(directory):\n",
    "    hostnames = tuple(read_benchmark_hostnames(directory.joinpath(\"network_hosts.txt\")))\n",
    "    with netCDF4.Dataset(directory.joinpath(\"network_median.nc\"), \"r\")  as dataset:\n",
    "        step_len = dataset[\"step_length\"][0]\n",
    "        start_len = dataset[\"begin_mes_length\"][0]\n",
    "        end_len = dataset[\"end_mes_length\"][0]\n",
    "        \n",
    "        assert len(hostnames) == dataset[\"proc_num\"][0]\n",
    "        assert dataset[\"test_type\"][0] == 1\n",
    "        assert start_len == 0\n",
    "        assert end_len == 10000  # last message length should be 9900\n",
    "        assert step_len == 100\n",
    "        steps = (end_len - start_len) // step_len - 1\n",
    "        assert start_len + (steps + 1) * step_len == end_len\n",
    "        \n",
    "        lengths = range(start_len, end_len, step_len)\n",
    "        \n",
    "        data = {\n",
    "            length: pd.DataFrame(dataset[\"data\"][index], index=hostnames, columns=hostnames)\n",
    "            for (index, length) in enumerate(lengths)\n",
    "        }\n",
    "        panel = pd.Panel(data)  # most top-level index is length of message\n",
    "    return TestResults(hostnames=hostnames, medians=panel, msg_lengths=list(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_results = import_data(TEST_RESULT_DIRECTORIES[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure that all classes were covered by our test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_all_classes_covered(hostnames):\n",
    "    \"\"\"Fails an assertion if there is a class of pairs\n",
    "    that was not covered by the test\"\"\"\n",
    "    pairs_tested = node_pairs[\n",
    "        node_pairs[\"node1\"].isin(hostnames) &\n",
    "        node_pairs[\"node2\"].isin(hostnames)\n",
    "    ]\n",
    "    assert len(pairs_tested[\"class_\"].unique()) == len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check_all_classes_covered(test_results.hostnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ClassGetter():\n",
    "    def __init__(self, node_pairs):\n",
    "        self._reverse_lookup_table = node_pairs.set_index([\"node1\", \"node2\"])\n",
    "    \n",
    "    def __call__(self, node1, node2):\n",
    "        min_node = min(node1, node2)\n",
    "        max_node = max(node1, node2)\n",
    "        return self._reverse_lookup_table.loc[min_node].loc[max_node].loc[\"class_\"]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_class = ClassGetter(node_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def uniques_in_matrix(matrix):\n",
    "    return frozenset(matrix[col].loc[row] for col in matrix.columns for row in matrix.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test uniques_in_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_uniques_in_matrix():\n",
    "    uniques1 = uniques_in_matrix(\n",
    "        pd.DataFrame([[1, 2, 3], [4, 5, 6], [7, 8, 9]], columns=[\"c1\", \"c2\", \"c3\"], index=[\"i1\", \"i2\", \"i3\"])\n",
    "    )\n",
    "    assert frozenset({1, 2, 3, 4, 5, 6, 7, 8, 9}) == uniques1\n",
    "    \n",
    "    uniques2 = uniques_in_matrix(\n",
    "        pd.DataFrame([[1, 2, 3], [4, 5, 6], [7, 8, 9]], columns=[\"i1\", \"i2\", \"i3\"], index=[\"i1\", \"i2\", \"i3\"])\n",
    "    )\n",
    "    assert uniques2 == uniques1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_uniques_in_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count unique values in medians matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_unique_medians(medians):\n",
    "    uniques_counts = [len(uniques_in_matrix(medians.iloc[i])) for i in range(len(medians))]\n",
    "    ind_with_min_count, min_count = min(enumerate(uniques_counts), key=lambda pair: pair[1])\n",
    "    ind_with_max_count, max_count = max(enumerate(uniques_counts), key=lambda pair: pair[1])\n",
    "    print(\n",
    "        \"Minimum number of unique values in matrix is {0}. Message length = {1}.\"\n",
    "            .format(min_count, medians.keys()[ind_with_min_count])\n",
    "    )\n",
    "    print(\n",
    "        \"Maximum number of unique values in matrix is {0}. Message length = {1}.\"\n",
    "            .format(max_count, medians.keys()[ind_with_max_count])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_all_unique_counts():\n",
    "    for directory in TEST_RESULT_DIRECTORIES:\n",
    "        medians = import_data(directory).medians\n",
    "        print(directory.basename())\n",
    "        count_unique_medians(medians)\n",
    "\n",
    "# print_all_unique_counts()  # this takes a lot of time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matrix_to_table(matrix):\n",
    "    table = matrix.stack().reset_index()\n",
    "    table.columns = [\"node1\", \"node2\", \"ping\"]\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Predictor():\n",
    "    \"\"\"Predicts ping for a packet with specific message_size between 2 nodes,\n",
    "    measured in seconds.\"\"\"\n",
    "    def __init__(self, test_results):\n",
    "        # construct extended node_pairs table for join\n",
    "        inversed_node_pairs = node_pairs.rename(columns={\"node1\": \"node2\", \"node2\": \"node1\"})\n",
    "        node_pairs_dup = pd.concat(\n",
    "            [node_pairs, inversed_node_pairs],\n",
    "            ignore_index = True, verify_integrity=True\n",
    "        ) \\\n",
    "            .drop_duplicates(subset=[\"node1\", \"node2\"]) \\\n",
    "            .set_index([\"node1\", \"node2\"], verify_integrity=True)\n",
    "        \n",
    "        # prepare pings matrices for join\n",
    "        pings = (matrix_to_table(df).set_index([\"node1\", \"node2\"], verify_integrity=True)\n",
    "                 for (_, df) in test_results.medians.iteritems())\n",
    "        \n",
    "        # build tables with 2 columns each: class_, ping. There will be many rows with same class_\n",
    "        pings_classes = (\n",
    "            df.join(node_pairs_dup, how=\"left\").reset_index(drop=True)\n",
    "            for df in pings\n",
    "        )\n",
    "        \n",
    "        # reverse lookup table (by message length and class)\n",
    "        self._data = pd.concat(\n",
    "            {\n",
    "                msg_length: df.groupby(\"class_\").mean()\n",
    "                for (msg_length, df) in zip(test_results.msg_lengths, pings_classes)\n",
    "            },\n",
    "            names=[\"msg_len\", \"class_\"]\n",
    "        ).rename(columns={\"ping\": \"mean_of_medians_ping\"})\n",
    "    \n",
    "    def predict(self, msg_len, node1, node2):\n",
    "        \"\"\"This function takes about 1ms\"\"\"\n",
    "        return self._data.loc[msg_len, get_class(node1, node2)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictor = Predictor(test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try predicting stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert predictor.predict(4000, \"n48003\", \"n48009\") == 5.3229932539018043e-06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure prediction speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n48001 n48006\n"
     ]
    }
   ],
   "source": [
    "print(*node_pairs.iloc[5][[\"node1\", \"node2\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 1: 1.05 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r1\n",
    "predictor.predict(\n",
    "    choice(test_results.msg_lengths),\n",
    "    *node_pairs.iloc[randint(0, len(node_pairs) - 1)][[\"node1\", \"node2\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_class_pairs=pd.DataFrame(\n",
    "    [[500, 4, \"foo\"], [400, 3, \"bar\"], [6300, 0, \"bazz\"], [400, 6, \"hi\"]],\n",
    "    columns=[\"msg_len\", \"class_\", \"text\"]\n",
    ").set_index([\"msg_len\", \"class_\"], drop=True, verify_integrity=True).sort_index() \\\n",
    "    .drop([\"text\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>msg_len</th>\n",
       "      <th>class_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">400</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6300</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [(400, 3), (400, 6), (500, 4), (6300, 0)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_class_pairs.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean_of_medians_ping</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>msg_len</th>\n",
       "      <th>class_</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">400</th>\n",
       "      <th>3</th>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <th>4</th>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6300</th>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                mean_of_medians_ping\n",
       "msg_len class_                      \n",
       "400     3                   0.000005\n",
       "        6                   0.000005\n",
       "500     4                   0.000005\n",
       "6300    0                   0.000000"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor._data.join(size_class_pairs, how=\"right\")  # not implemented :()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate on all other tests results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
