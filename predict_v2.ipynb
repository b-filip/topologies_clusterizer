{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from path import Path  # pip install --user path.py\n",
    "import re\n",
    "from IPython.display import display\n",
    "from pprint import pprint\n",
    "import netCDF4\n",
    "from IPython.core.debugger import Pdb\n",
    "from collections import namedtuple\n",
    "from random import randint, choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load seaborn and other stuff for visualization\n",
    "#import seaborn  # pip install --user seaborn\n",
    "#from matplotlib import pyplot as plt\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def debug_here():\n",
    "    Pdb().set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = pd.read_pickle(\"classes.pkl\")\n",
    "node_pairs = pd.read_pickle(\"paths_with_classes.pkl\").drop(\"shortest_path\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST_RESULT_DIRECTORIES = Path(\"/home/shibbiry/Dropbox/documents/msu/bachelors_thesis_cluster_topology/test_results\") \\\n",
    "    .dirs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_benchmark_hostnames(path_to_file):\n",
    "    lines = path_to_file.lines()\n",
    "    return (re.match(r\"^(n\\d{5})\\.\", line).groups()[0] for line in lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TestResults = namedtuple(\"TestResults\", [\"hostnames\", \"medians\", \"msg_lengths\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_MSG_LEN = 0\n",
    "END_MSG_LEN = 10000\n",
    "MSG_LEN_STEP = 100\n",
    "STEPS = (END_MSG_LEN - START_MSG_LEN) // MSG_LEN_STEP - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def import_data(directory):\n",
    "    hostnames = tuple(read_benchmark_hostnames(directory.joinpath(\"network_hosts.txt\")))\n",
    "    with netCDF4.Dataset(directory.joinpath(\"network_median.nc\"), \"r\")  as dataset:\n",
    "        step_len = dataset[\"step_length\"][0]\n",
    "        start_len = dataset[\"begin_mes_length\"][0]\n",
    "        end_len = dataset[\"end_mes_length\"][0]\n",
    "        \n",
    "        assert len(hostnames) == dataset[\"proc_num\"][0]\n",
    "        assert dataset[\"test_type\"][0] == 1\n",
    "        assert start_len == START_MSG_LEN\n",
    "        assert end_len == END_MSG_LEN  # last message length should be 9900\n",
    "        assert step_len == MSG_LEN_STEP\n",
    "        steps = (end_len - start_len) // step_len - 1\n",
    "        assert start_len + (steps + 1) * step_len == end_len\n",
    "        \n",
    "        lengths = range(start_len, end_len, step_len)\n",
    "        \n",
    "        data = {\n",
    "            length: pd.DataFrame(dataset[\"data\"][index], index=hostnames, columns=hostnames)\n",
    "            for (index, length) in enumerate(lengths)\n",
    "        }\n",
    "        panel = pd.Panel(data)  # most top-level index is length of message\n",
    "    return TestResults(hostnames=hostnames, medians=panel, msg_lengths=list(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_results = import_data(TEST_RESULT_DIRECTORIES[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure that all classes were covered by our test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_all_classes_covered(hostnames):\n",
    "    \"\"\"Fails an assertion if there is a class of pairs\n",
    "    that was not covered by the test\"\"\"\n",
    "    pairs_tested = node_pairs[\n",
    "        node_pairs[\"node1\"].isin(hostnames) &\n",
    "        node_pairs[\"node2\"].isin(hostnames)\n",
    "    ]\n",
    "    assert len(pairs_tested[\"class_\"].unique()) == len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check_all_classes_covered(test_results.hostnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build extended_node_pairs with index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_extended_node_pairs(node_pairs):\n",
    "    inversed_node_pairs = node_pairs.rename(columns={\"node1\": \"node2\", \"node2\": \"node1\"})\n",
    "    return pd.concat(\n",
    "        [node_pairs, inversed_node_pairs],\n",
    "        ignore_index = True, verify_integrity=True\n",
    "    ) \\\n",
    "        .drop_duplicates(subset=[\"node1\", \"node2\"]) \\\n",
    "        .set_index([\"node1\", \"node2\"], verify_integrity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extended_node_pairs = build_extended_node_pairs(node_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_class(node1, node2):\n",
    "    return extended_node_pairs.loc[node1].loc[node2].loc[\"class_\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def uniques_in_matrix(matrix):\n",
    "    return frozenset(matrix[col].loc[row] for col in matrix.columns for row in matrix.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test uniques_in_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_uniques_in_matrix():\n",
    "    uniques1 = uniques_in_matrix(\n",
    "        pd.DataFrame([[1, 2, 3], [4, 5, 6], [7, 8, 9]], columns=[\"c1\", \"c2\", \"c3\"], index=[\"i1\", \"i2\", \"i3\"])\n",
    "    )\n",
    "    assert frozenset({1, 2, 3, 4, 5, 6, 7, 8, 9}) == uniques1\n",
    "    \n",
    "    uniques2 = uniques_in_matrix(\n",
    "        pd.DataFrame([[1, 2, 3], [4, 5, 6], [7, 8, 9]], columns=[\"i1\", \"i2\", \"i3\"], index=[\"i1\", \"i2\", \"i3\"])\n",
    "    )\n",
    "    assert uniques2 == uniques1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_uniques_in_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count unique values in medians matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_unique_medians(medians):\n",
    "    uniques_counts = [len(uniques_in_matrix(medians.iloc[i])) for i in range(len(medians))]\n",
    "    ind_with_min_count, min_count = min(enumerate(uniques_counts), key=lambda pair: pair[1])\n",
    "    ind_with_max_count, max_count = max(enumerate(uniques_counts), key=lambda pair: pair[1])\n",
    "    print(\n",
    "        \"Minimum number of unique values in matrix is {0}. Message length = {1}.\"\n",
    "            .format(min_count, medians.keys()[ind_with_min_count])\n",
    "    )\n",
    "    print(\n",
    "        \"Maximum number of unique values in matrix is {0}. Message length = {1}.\"\n",
    "            .format(max_count, medians.keys()[ind_with_max_count])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_all_unique_counts():\n",
    "    for directory in TEST_RESULT_DIRECTORIES:\n",
    "        medians = import_data(directory).medians\n",
    "        print(directory.basename())\n",
    "        count_unique_medians(medians)\n",
    "\n",
    "# print_all_unique_counts()  # this takes a lot of time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matrix_to_table(matrix):\n",
    "    table = matrix.stack().reset_index()\n",
    "    table.columns = [\"node1\", \"node2\", \"ping\"]\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Predictor():\n",
    "    \"\"\"Predicts ping for a packet with specific message_size between 2 nodes,\n",
    "    measured in seconds.\"\"\"\n",
    "    def __init__(self, test_results):\n",
    "        # prepare pings matrices for join\n",
    "        pings = (matrix_to_table(df).set_index([\"node1\", \"node2\"], verify_integrity=True)\n",
    "                 for (_, df) in test_results.medians.iteritems())\n",
    "        \n",
    "        # build tables with 2 columns each: class_, ping. There will be many rows with same class_\n",
    "        pings_classes = (\n",
    "            df.join(extended_node_pairs, how=\"left\").reset_index(drop=True)\n",
    "            for df in pings\n",
    "        )\n",
    "        \n",
    "        # reverse lookup table (by message length and class)\n",
    "        self._data = pd.concat(\n",
    "            {\n",
    "                msg_length: df.groupby(\"class_\").mean()\n",
    "                for (msg_length, df) in zip(test_results.msg_lengths, pings_classes)\n",
    "            },\n",
    "            names=[\"msg_len\", \"class_\"]\n",
    "        ).rename(columns={\"ping\": \"mean_of_medians_ping\"})\n",
    "    \n",
    "    def predict(self, msg_len, node1, node2):\n",
    "        \"\"\"This function takes about 1ms\"\"\"\n",
    "        return self._data.loc[msg_len, get_class(node1, node2)][0]\n",
    "    \n",
    "    def predict_many(self, df):\n",
    "        \"\"\"df must have columns: msg_len, node1, node2\"\"\"\n",
    "        return df \\\n",
    "            .join(extended_node_pairs, on=[\"node1\", \"node2\"], how=\"left\") \\\n",
    "            .join(predictor._data, on=[\"msg_len\", \"class_\"], how=\"left\") \\\n",
    "            .rename(columns={\"mean_of_medians_ping\": \"predicted_ping\"}) \\\n",
    "            [[\"node1\", \"node2\", \"predicted_ping\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictor = Predictor(test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try predicting stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0067901611328125e-06"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict(3900, \"n48003\", \"n48009\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictor.get_clas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-bfbf35c928a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n48003\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n48009\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5.3229932539018043e-06\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert predictor.predict(4000, \"n48003\", \"n48009\") == 5.3229932539018043e-06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure prediction speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*node_pairs.iloc[5][[\"node1\", \"node2\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r1\n",
    "predictor.predict(\n",
    "    choice(test_results.msg_lengths),\n",
    "    *node_pairs.iloc[randint(0, len(node_pairs) - 1)][[\"node1\", \"node2\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing predict_many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_random_samples(count):\n",
    "    return node_pairs.sample(n=count)[[\"node1\", \"node2\"]] \\\n",
    "        .assign(msg_len=np.random.randint(0, STEPS, size=count) * MSG_LEN_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = get_random_samples(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "predictor.predict_many(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate on all other tests results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
