{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from openpyxl import load_workbook # pip install --user openpyxl\n",
    "from itertools import chain, islice, zip_longest\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from bidict import frozenbidict # pip install --user bidict\n",
    "from functools import reduce, wraps, partial\n",
    "import networkx as nx # pip install --user networkx\n",
    "from pprint import pprint\n",
    "import os.path\n",
    "from libcrap.core import calcsave_or_load # pip install --user libcrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# path to \"cable journal\" excel file\n",
    "# it's a MS Excel spreadsheet with a list of node connections\n",
    "# in Lomonosov 2 cluster\n",
    "# I am not allowed to share it.\n",
    "SPREADSHEET_FILENAME = r'wire_journal_48_53.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# regex for parsing rack number and other numbers from cells\n",
    "# with switch names in the spreadsheet\n",
    "switch_regex = re.compile(\n",
    "    r\"\"\"\n",
    "    КГК\\.       # literally match what is written here\n",
    "    (?P<rack>\\d+)\\.        # rack number is one or more digits, followed by dot\n",
    "    (?P<second_number>\\d+)\\.            # then goes another non-negative integer followed by dot\n",
    "    (?P<last_number>\\d+)            # and another integer of the same form\n",
    "    \"\"\",\n",
    "    re.VERBOSE)\n",
    "\n",
    "assert switch_regex.match(\"КГК.63.2.4\").groups() == (\"63\", \"2\", \"4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse data from the spreadsheet using openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_column_name(column):\n",
    "    \"\"\"Takes column as tuple as argument and returns\n",
    "    its name as string\"\"\"\n",
    "    return column[0].column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def extract_columns(worksheet, column_names):\n",
    "    \"\"\"\n",
    "    parameters:\n",
    "        worksheet -- worksheet\n",
    "        column_names -- list of strings, for example\n",
    "            ['A', 'C', 'E']\n",
    "    returns:\n",
    "        list of columns, where every column is represented\n",
    "        as a tuple\"\"\"\n",
    "    all_columns = worksheet.columns\n",
    "    extracted_columns = [col for col in all_columns\n",
    "                         if get_column_name(col) in column_names]\n",
    "    assert len(extracted_columns) == len(column_names)\n",
    "    return extracted_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def columns_to_tuples(columns):\n",
    "    \"\"\"parameters:\n",
    "        columns -- columns as a tuple/list of tuples\n",
    "    returns:\n",
    "        list of lists/tuples, each one represents a row\"\"\"\n",
    "    return [[cell.value for cell in row] for row in zip(*columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def parse_switch_pairs(workbook):\n",
    "    \"\"\"Parse openpyxl workbook and extract a list of\n",
    "    pairs of switches. Pair (A, B) means that swithes A\n",
    "    and B are connected.\n",
    "    Returns list of pairs of strings.\"\"\"\n",
    "    return list(chain(*[columns_to_tuples(extract_columns(worksheet, ['C', 'K']))\n",
    "            for worksheet in workbook]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Lomonosov2's racks are grouped into pairs\n",
    "# Switches in the same rack or pair of racks are connected with copper wires\n",
    "# Switches in different pairs of racks are connected with optic cable\n",
    "RACK_PAIRS = ((48, 49), (50, 51), (52, 53))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_rack(switch_name):\n",
    "    \"\"\"Determines rack number from switch name\"\"\"\n",
    "    return int(switch_regex.match(switch_name).group('rack'))\n",
    "\n",
    "assert get_rack('КГК.48.0.1') == 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def determine_material_between_switches(rack1, rack2):\n",
    "    \"\"\"Switches have different material between them.\n",
    "    See comment about RACK_PAIRS.\n",
    "    \n",
    "    This function determines cable material between two switches\n",
    "    by using their rack numbers and returns it as string\"\"\"\n",
    "    racks = (rack1, rack2)\n",
    "    if any(\n",
    "            all(rack in rack_pair for rack in racks)\n",
    "            for rack_pair in RACK_PAIRS):\n",
    "        # they are in the same pair of racks\n",
    "        return 'copper'\n",
    "    return 'optic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_cable_material_from_row(row):\n",
    "    rack1 = row.loc[\"switch1_rack\"]\n",
    "    rack2 = row.loc[\"switch2_rack\"]\n",
    "    return determine_material_between_switches(rack1, rack2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_second_number(switch_name):\n",
    "    return switch_regex.match(switch_name).groups()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_third_number(switch_name):\n",
    "    return switch_regex.match(switch_name).groups()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "workbook = load_workbook(SPREADSHEET_FILENAME, data_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "switch_pairs = parse_switch_pairs(workbook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "switches = pd.DataFrame({\n",
    "    \"name\": sorted(list(frozenset(chain(*switch_pairs))))\n",
    "})\n",
    "switches[\"rack_number\"] = switches[\"name\"].apply(get_rack)\n",
    "switches[\"second_number\"] = switches[\"name\"].apply(get_second_number)\n",
    "switches[\"third_number\"] = switches[\"name\"].apply(get_third_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "switches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "switch_to_switch_connections = (\n",
    "    # add rack numbers for switch1 column\n",
    "    pd.merge(\n",
    "        # convert list of pairs to DataFrame\n",
    "        pd.DataFrame.from_records(switch_pairs, columns=[\"switch1\", \"switch2\"]),\n",
    "        switches,\n",
    "        left_on=[\"switch1\"], right_on=[\"name\"])\n",
    "    .rename(columns={\"rack_number\": \"switch1_rack\"})\n",
    "    [[\"switch1\", \"switch2\", \"switch1_rack\"]]\n",
    "    \n",
    "    # add rack numbers for switch2 column\n",
    "    .merge(\n",
    "        switches,\n",
    "        left_on=[\"switch2\"], right_on=[\"name\"])\n",
    "    .rename(columns={\"rack_number\": \"switch2_rack\"})\n",
    "    [[\"switch1\", \"switch2\", \"switch1_rack\", \"switch2_rack\"]]\n",
    "    \n",
    "    # add cable type\n",
    "    .assign(cable_type=lambda df: df.apply(\n",
    "        lambda row: determine_material_between_switches(row[\"switch1_rack\"], row[\"switch2_rack\"]),\n",
    "        axis=1\n",
    "    ))\n",
    "    .drop([\"switch1_rack\", \"switch2_rack\"], axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "switch_to_switch_connections.iloc[510:513]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build table with connections between switches and computational\n",
    "nodes connected directly to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_matching_computational_nodes(switch):\n",
    "    \"\"\"params:\n",
    "        switch -- string, name of the switch\n",
    "    returns:\n",
    "        list of strings which are names of computational\n",
    "        nodes connected to this switch\"\"\"\n",
    "    get_thingie = switch_regex.match(switch).group\n",
    "    return [\n",
    "        'n{0}{1}{2:02d}'.format(\n",
    "            get_thingie('rack'),\n",
    "            get_thingie('second_number'),\n",
    "            (int(get_thingie('last_number')) - 1) * 8 + i\n",
    "        )\n",
    "        for i in range(1, 9)\n",
    "    ]\n",
    "\n",
    "assert get_matching_computational_nodes(\"КГК.48.2.3\") == [\n",
    "    'n48217',\n",
    "    'n48218',\n",
    "    'n48219',\n",
    "    'n48220',\n",
    "    'n48221',\n",
    "    'n48222',\n",
    "    'n48223',\n",
    "    'n48224'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "comp_node_to_switch_connects = pd.concat(\n",
    "    (pd.DataFrame.from_dict({\n",
    "        \"computational_node\": get_matching_computational_nodes(switch),\n",
    "        \"switch\": switch})\n",
    "    for switch in switches[\"name\"]),\n",
    "    ignore_index=True\n",
    ")\n",
    "assert len(comp_node_to_switch_connects) == 1536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comp_node_to_switch_connects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build table with all graph edges, that is a single table\n",
    "with switch-switch and switch-comp_node connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "edges = pd.concat([\n",
    "    switch_to_switch_connections\n",
    "        .rename(columns={\n",
    "            \"switch1\": \"node1\",\n",
    "            \"switch2\": \"node2\",\n",
    "            \"cable_type\": \"connection_type\"\n",
    "        }),\n",
    "    comp_node_to_switch_connects\n",
    "        .rename(columns={\n",
    "            \"computational_node\": \"node1\",\n",
    "            \"switch\": \"node2\"\n",
    "        })\n",
    "        .assign(connection_type=\"backplane\")\n",
    "])\n",
    "edges[\"connection_type\"] = edges[\"connection_type\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "edges.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make a table with all nodes and all their properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nodes = pd.concat([\n",
    "    switches[[\"name\"]]\n",
    "        .assign(type_=\"switch\"),\n",
    "    comp_node_to_switch_connects[[\"computational_node\"]]\n",
    "        .rename(columns={\"computational_node\": \"name\"})\n",
    "        .assign(type_=\"computational\")\n",
    "])\n",
    "nodes[\"type_\"] = nodes[\"type_\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want to make copies of these 2 tables with all nodes' and edges' properties\n",
    "replaced with numbers. Categorical values (like computational, switch) or\n",
    "(copper, backplane, optic) should be translated to numbers like 0, 1, 2.\n",
    "\n",
    "Then I will calculate shortest path for every pair of nodes (we will assume that\n",
    "every edge has the same weight) and I will write down a sequence of numbers which\n",
    "will mean the sequence of properties of all nodes and edges in the shortest\n",
    "path.\n",
    "\n",
    "E.g. `(comp_node) --backplane-- (switch) --optic-- (switch) --backplane-- (comp_node)`\n",
    "might get translated to **1,2,0,1,0,2,1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def map_categorial_sequence_to_numbers(sequence):\n",
    "    \"\"\"Takes a sequence of values as input.\n",
    "    Maps each unique value to an integer.\n",
    "    \n",
    "    Returns a tuple: (\n",
    "      the same sequence as numpy.ndarray of resulting integers\n",
    "      ,\n",
    "      mapping\n",
    "    )\"\"\"\n",
    "    new_sequence, unique_values = pd.factorize(sequence, sort=True)\n",
    "    return new_sequence, frozenbidict(enumerate(unique_values)).inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def map_categorial_df_to_numbers(df, columns):\n",
    "    \"\"\"Arguments:\n",
    "    df -- pandas.DataFrame in which we will transform columns (not inplace)\n",
    "    columns -- sequence of column names\n",
    "    \n",
    "    Returns a tuple (new_data_frame, mappings)\n",
    "    new_data_frame is a DataFrame with `columns` values replaced with\n",
    "      what they were mapped to\n",
    "    mappings - a sequence of frozenbidicts with mappings of values,\n",
    "    one for each column. These bidicts are ordered the same way\n",
    "    as the argument `columns`.\"\"\"\n",
    "    assert type(df) == pd.DataFrame\n",
    "    mappings = []\n",
    "    new_df = df.copy()\n",
    "    for column in columns:\n",
    "        new_df[column], mapping = map_categorial_sequence_to_numbers(df[column])\n",
    "        mappings.append(mapping)\n",
    "    return new_df, mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def test_map_categorial_df_to_numbers():\n",
    "    df = pd.DataFrame.from_records(\n",
    "        [\n",
    "            (\"john\", \"male\", \"high\"),\n",
    "            (\"lisa\", \"female\", \"low\"),\n",
    "            (\"jack\", \"male\", \"low\"),\n",
    "            (\"anna\", \"female\", \"medium\"),\n",
    "            (\"boris\", \"male\", \"medium\")\n",
    "        ],\n",
    "        columns=[\"name\", \"sex\", \"height\"]\n",
    "    )\n",
    "    new_df, mappings = map_categorial_df_to_numbers(df, [\"height\", \"sex\"])\n",
    "    display(mappings)\n",
    "    display(new_df)\n",
    "\n",
    "#test_map_categorial_df_to_numbers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nodes_with_numerical_properties, nodes_mappings = map_categorial_df_to_numbers(\n",
    "    nodes, [\"type_\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "edges_with_numerical_properties, edges_mappings = map_categorial_df_to_numbers(\n",
    "    edges, [\"connection_type\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(nodes_mappings)\n",
    "display(nodes_with_numerical_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(edges_mappings)\n",
    "display(edges_with_numerical_properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will create NetworkX graph from these 2 tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "topology = nx.Graph()\n",
    "for index, row in nodes_with_numerical_properties.iterrows():\n",
    "    node_name = row[\"name\"]\n",
    "    attributes = row.drop([\"name\"]).to_dict()\n",
    "    topology.add_node(node_name, attr_dict=attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for index, row in edges_with_numerical_properties.iterrows():\n",
    "    node1_name = row[\"node1\"]\n",
    "    node2_name = row[\"node2\"]\n",
    "    attributes = row.drop([\"node1\", \"node2\"]).to_dict()\n",
    "    topology.add_edge(node1_name, node2_name, attr_dict=attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will find shortest path for every pair of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this is a pandas Series of all computational nodes\n",
    "comp_nodes = nodes[nodes[\"type_\"] ==\"computational\"][\"name\"]\n",
    "display(comp_nodes.head(2))\n",
    "display(comp_nodes.tail(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd_diskcache = partial(calcsave_or_load, load_func=pd.read_pickle, save_func=pd.to_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@pd_diskcache(\"paths.pkl\")\n",
    "def find_comp_to_comp_shortest_paths(topology, comp_nodes):\n",
    "    paths_ugly = nx.all_pairs_shortest_path(topology)\n",
    "    # calculates shortest paths and stores them in a dict of dicts\n",
    "    \n",
    "    # build a table with all computational node pairs\n",
    "    # they are not duplicated\n",
    "    # if there is (\"n48001\", \"n49419\") then there is no (\"n49419\", \"n48001\") pair\n",
    "    comp_node_pairs = pd.DataFrame.from_records(\n",
    "        chain.from_iterable(\n",
    "            [(node1, node2) for node2 in comp_nodes.iloc[index+1:]]\n",
    "            for (index, node1) in comp_nodes.iteritems()\n",
    "        ),\n",
    "        columns=[\"node1\", \"node2\"]\n",
    "    )\n",
    "\n",
    "    # write shortest paths to this table\n",
    "    comp_node_pairs[\"shortest_path\"] = comp_node_pairs.apply(\n",
    "        lambda row: paths_ugly[row.loc[\"node1\"]][row.loc[\"node2\"]],\n",
    "        axis=1\n",
    "    )\n",
    "    return comp_node_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# shortest paths between all computational nodes\n",
    "paths = find_comp_to_comp_shortest_paths(topology, comp_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(paths.iloc[400:404])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's convert these lists of nodes to lists of properties.\n",
    "Edges have properties, nodes have properties - let's make lists\n",
    "of those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_node_properties(topology, node):\n",
    "    \"\"\"Returns node properties as a dict.\"\"\"\n",
    "    return topology.node[node]\n",
    "\n",
    "assert get_node_properties(topology, \"КГК.48.0.3\") == {\"type_\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_edge_properties(topology, node1, node2):\n",
    "    \"\"\"Returns edge properties as a dict.\"\"\"\n",
    "    return topology.edge[node1][node2]\n",
    "\n",
    "def test_get_edge_properties():\n",
    "    correct_result = {\"connection_type\": 0}\n",
    "    result1 = get_edge_properties(topology, \"КГК.48.0.3\", \"n48022\")\n",
    "    result2 = get_edge_properties(topology, \"n48022\", \"КГК.48.0.3\")\n",
    "    assert result1 == correct_result == result2\n",
    "\n",
    "test_get_edge_properties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def interleave(it1, it2):\n",
    "    return (\n",
    "        item for item\n",
    "        in chain.from_iterable(zip_longest(it1, it2))\n",
    "        if item is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def path_to_properties(topology, path):\n",
    "    # path[0] is a node\n",
    "    property0 = [get_node_properties(topology, path[0])]\n",
    "    \n",
    "    nodes_properties = (get_node_properties(topology, node) for node in path)\n",
    "    \n",
    "    edges_properties = (get_edge_properties(topology, node1, node2)\n",
    "                        for (node1, node2) in zip(path[:-1], path[1:]))\n",
    "    return list(interleave(nodes_properties, edges_properties))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@pd_diskcache(\"paths_properties.pkl\")\n",
    "def calc_paths_properties(topology, paths):\n",
    "    paths_properties = paths.copy()\n",
    "    paths_properties[\"shortest_path_properties\"] = \\\n",
    "        paths[\"shortest_path\"].apply(partial(path_to_properties, topology))\n",
    "    return paths_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 1\n",
    "paths_properties = paths.copy()\n",
    "paths_properties[\"shortest_path_properties\"] = \\\n",
    "    paths[\"shortest_path\"].apply(partial(path_to_properties, topology))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(paths_properties.iloc[0][\"shortest_path\"])\n",
    "display(paths_properties.iloc[0][\"shortest_path_properties\"])"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
